{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a61749",
   "metadata": {},
   "source": [
    "# \"[MachineLearning] Ensemble Learning - Overview\"\n",
    "> KNU AIR week4\n",
    "\n",
    "- toc: false\n",
    "- badges: false\n",
    "- comments: false\n",
    "- categories: [ensemble learning]\n",
    "- hide_{github,colab,binder,deepnote}_badge: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935060d6",
   "metadata": {},
   "source": [
    "__Content creators:__ 이주형, 이중원\n",
    "\n",
    "__Content reviewers:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05813563",
   "metadata": {},
   "source": [
    "# 1. Overview\n",
    "\n",
    "### No Free Lunch Theorem\n",
    "+ There is no classification method to be superior or inferior overall.\n",
    "+ Obtaining good generalization performance, there is no context-independent or usage-independent reasons to favor one algorithm over others.\n",
    "+ If one algorithm seems to outperform another in a particular situation, it is a consequence of its fit to a particular pattern recognition problem.\n",
    "+ In practice, experience with a broad range of techniques is the best insurance for solving arbitrary new classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ec9e9",
   "metadata": {},
   "source": [
    "### Bias and Variance\n",
    "+ **Bias** : the amount by which the average estimator differs from the truth\n",
    "    + Low Bias : on average, we will accurately estimate the function from the dataset\n",
    "    + High Bias : implies a poor match\n",
    "+ **Variance** : spread of the individual estimations around their mean\n",
    "    + Low Variance : estimated function does not change much with different datasets\n",
    "    + High Variance : implies a weak match\n",
    "+ Bias and variance are *not independent* of each other\n",
    "\n",
    "### Model Complexity\n",
    "+ Lower model complexity : high bias & low variance -> **Boosting**\n",
    "    + Logistic regression, LDA, k-NN with large k\n",
    "+ Higher model complexity : low bias & high variance -> **Bagging**\n",
    "    + DT, ANN, SVM, k-NN with small k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894113b0",
   "metadata": {},
   "source": [
    "### Purpose of Ensemble\n",
    "+ Goal : Reduce the error through constructing multiple learners to reduce bias and variance\n",
    "+ To construct good ensemble systems, each base classifier component should achieve **sufficient degree of diversity**, and properly combine the outputs of individual classifiers.\n",
    "\n",
    "[Reference](https://github.com/pilsung-kang/Business-Analytics-IME654-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
