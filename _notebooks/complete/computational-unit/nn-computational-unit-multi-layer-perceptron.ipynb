{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a61749",
   "metadata": {},
   "source": [
    "# \"[NeuralNetwork] Computational Unit - Multi Layer Perceptron\"\n",
    "> KNU AIR week4\n",
    "\n",
    "- toc: false\n",
    "- badges: false\n",
    "- comments: false\n",
    "- categories: [computational unit]\n",
    "- hide_{github,colab,binder,deepnote}_badge: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935060d6",
   "metadata": {},
   "source": [
    "__Content creators:__ HEESUNG YANG\n",
    "\n",
    "__Content reviewers:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05813563",
   "metadata": {},
   "source": [
    "# 1. Overview\n",
    "- First model for supervised neural network, in 1957\n",
    "- Single-layer single-output neural network for binary classification of linearly separable dataset\n",
    "- Model :\n",
    "\n",
    "$\n",
    "\\text{For} \\,\\ \\mathbf{x} = [x_1, \\,\\ \\cdots, \\,\\ x_m]^T \\,\\ \\text{and} \\,\\ \n",
    "W_1 = \n",
    "\\begin{bmatrix}\n",
    "w_{1, 1}^{(1)} & \\cdots & w_{1, m}^{(1)} \\\\\n",
    "w_{2, 1}^{(1)} & \\cdots & w_{2, m}^{(1)} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "w_{n, 1}^{(1)} & \\cdots & w_{n, m}^{(1)} \\\\\n",
    "\\end{bmatrix}, \\,\\\n",
    "W_2 = \n",
    "\\begin{bmatrix}\n",
    "w_{1, 1}^{(2)} & \\cdots & w_{1, n}^{(2)} \\\\\n",
    "w_{2, 1}^{(2)} & \\cdots & w_{2, n}^{(2)} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "w_{o, 1}^{(2)} & \\cdots & w_{o, n}^{(2)} \\\\\n",
    "\\end{bmatrix}, \\,\\\n",
    "$<br>\n",
    "\n",
    "$\n",
    "\\mathbf{b}_1 = [b_1^{(1)}, \\,\\ b_2^{(1)}, \\cdots \\,\\, b_n^{(1)}]^T, \\,\\ \\mathbf{b}_2 = [b_1^{(2)}, \\,\\ b_2^{(2)}, \\,\\,  \\cdots , \\,\\ b_o^{(2)}]^T\n",
    "$,\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = \\text{softmax}(W_2\\sigma(W_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2).\n",
    "$$\n",
    "\n",
    "- Learning : Error back-propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c1318",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5280e98",
   "metadata": {},
   "source": [
    "# 2. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d2ed7-3eea-4327-ad1f-2a62a64bf205",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6842359-de38-45e8-95e4-8bffc8d6b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8773467c-40d8-40c0-a76a-73c02adce89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e727ab-581a-4700-b041-75b5c1432fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='dataset/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(), \n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='dataset/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a19de04-62fd-4c70-ba44-9972cf90518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c27bd2d-bd55-4d02-9e7f-05913487d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(image)\n",
    "            test_loss += loss_fn(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074d8c14-1fca-4102-b919-15985ebc2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5300dc6a-636f-4044-a4ac-a5626deb58f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH: 1], \tTest Loss: 0.1266, \tTest Accuracy: 48.11 %\n",
      "[EPOCH: 2], \tTest Loss: 0.1172, \tTest Accuracy: 64.19 %\n",
      "[EPOCH: 3], \tTest Loss: 0.1099, \tTest Accuracy: 74.16 %\n",
      "[EPOCH: 4], \tTest Loss: 0.1080, \tTest Accuracy: 75.35 %\n",
      "[EPOCH: 5], \tTest Loss: 0.1073, \tTest Accuracy: 75.81 %\n",
      "[EPOCH: 6], \tTest Loss: 0.1069, \tTest Accuracy: 75.96 %\n",
      "[EPOCH: 7], \tTest Loss: 0.1067, \tTest Accuracy: 76.21 %\n",
      "[EPOCH: 8], \tTest Loss: 0.1066, \tTest Accuracy: 76.47 %\n",
      "[EPOCH: 9], \tTest Loss: 0.1064, \tTest Accuracy: 76.55 %\n",
      "[EPOCH: 10], \tTest Loss: 0.1063, \tTest Accuracy: 76.58 %\n"
     ]
    }
   ],
   "source": [
    "for Epoch in range(1, training_epochs + 1):\n",
    "    train(model, train_data_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_data_loader)\n",
    "    print(\"[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\".format(\n",
    "        Epoch, test_loss, test_accuracy\n",
    "    ))\n",
    "    \n",
    "# 0.0362 loss -> log(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
